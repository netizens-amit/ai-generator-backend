import { JSONSchema7, ProviderV2, LanguageModelV2, EmbeddingModelV2 } from '@ai-sdk/provider';
import { Ollama, Options as Options$1 } from 'ollama';
import * as ai from 'ai';
import { ToolSet, generateText as generateText$1, LanguageModel, streamText as streamText$1 } from 'ai';

type OllamaWithWebSearch = Ollama;
/**
 * Configuration options for the web search tool
 */
interface WebSearchToolOptions {
    /**
     * Timeout for search requests in milliseconds
     * @default 30000
     */
    timeout?: number;
    /**
     * Ollama client instance to use for web search
     * If not provided, will need to be injected at runtime
     */
    client?: OllamaWithWebSearch;
}
/**
 * Output schema for web search results
 */
type WebSearchOutput = {
    results: Array<{
        title: string;
        url: string;
        snippet: string;
        publishedDate?: string;
    }>;
    searchQuery: string;
    totalResults: number;
};
declare function webSearch(options?: WebSearchToolOptions): ai.Tool<{
    query: string;
    maxResults?: number | undefined;
}, WebSearchOutput>;

type OllamaWithWebFetch = Ollama;
/**
 * Configuration options for the web fetch tool
 */
interface WebFetchToolOptions {
    /**
     * Timeout for fetch requests in milliseconds
     * @default 30000
     */
    timeout?: number;
    /**
     * Maximum content length to return in characters
     * @default 10000
     */
    maxContentLength?: number;
    /**
     * Ollama client instance to use for web fetch
     * If not provided, will need to be injected at runtime
     */
    client?: OllamaWithWebFetch;
}
/**
 * Output schema for web fetch results
 */
type WebFetchOutput = {
    content: string;
    title?: string;
    url: string;
    contentLength: number;
    error?: string;
};
/**
 * Creates a web fetch tool that allows AI models to retrieve content from specific URLs.
 *
 * This tool uses Ollama's web fetch capabilities to retrieve and parse web page content,
 * making it accessible to AI models for analysis, summarization, or answering questions
 * about specific web pages.
 *
 * @param options - Configuration options for the web fetch tool
 * @returns A tool that can be used in AI SDK generateText/streamText calls
 *
 * @example
 * ```typescript
 * import { generateText } from 'ai';
 * import { ollama } from 'ai-sdk-ollama';
 *
 * const result = await generateText({
 *   model: ollama('llama3.2'),
 *   prompt: 'Summarize the main points from this article: https://example.com/article',
 *   tools: {
 *     webFetch: ollama.tools.webFetch()
 *   }
 * });
 * ```
 */
declare function webFetch(options?: WebFetchToolOptions): ai.Tool<{
    url: string;
}, WebFetchOutput>;

/**
 * Ollama-specific tools that leverage the provider's web search capabilities.
 * Follows the same pattern as Google and OpenAI providers.
 */
declare const ollamaTools: {
    /**
     * Creates a web search tool that allows models to search the internet for current information.
     *
     * @param options - Configuration options for the web search tool
     * @returns A tool that can search the web and return relevant results
     *
     * @example
     * ```typescript
     * import { ollama } from 'ai-sdk-ollama';
     * import { generateText } from 'ai';
     *
     * const result = await generateText({
     *   model: ollama('llama3.2'),
     *   prompt: 'What are the latest AI developments?',
     *   tools: {
     *     webSearch: ollama.tools.webSearch({ maxResults: 5 })
     *   }
     * });
     * ```
     */
    readonly webSearch: typeof webSearch;
    /**
     * Creates a web fetch tool that allows models to retrieve content from specific URLs.
     *
     * @param options - Configuration options for the web fetch tool
     * @returns A tool that can fetch web page content
     *
     * @example
     * ```typescript
     * import { ollama } from 'ai-sdk-ollama';
     * import { generateText } from 'ai';
     *
     * const result = await generateText({
     *   model: ollama('llama3.2'),
     *   prompt: 'Summarize the content from https://example.com',
     *   tools: {
     *     webFetch: ollama.tools.webFetch()
     *   }
     * });
     * ```
     */
    readonly webFetch: typeof webFetch;
};

/**
 * Object Generation Reliability Utilities for Ollama
 *
 * This module provides utilities to make Ollama object generation more reliable
 * and deterministic. It addresses common issues like:
 * - Schema validation failures
 * - Inconsistent results across multiple attempts
 * - Timeout and fetch errors
 * - Malformed JSON responses
 * - Type mismatches (strings vs numbers)
 */

/**
 * A function that attempts to repair the raw output of the model
 * to enable JSON parsing and validation.
 *
 * Similar to AI SDK's RepairTextFunction but tailored for Ollama's output patterns.
 */
type RepairTextFunction = (options: {
    text: string;
    error: Error;
    schema?: JSONSchema7 | unknown;
}) => Promise<string | null>;
interface ObjectGenerationOptions {
    /**
     * Maximum number of retry attempts for object generation
     */
    maxRetries?: number;
    /**
     * Whether to attempt schema recovery when validation fails
     */
    attemptRecovery?: boolean;
    /**
     * Whether to use fallback values for failed generations
     */
    useFallbacks?: boolean;
    /**
     * Custom fallback values for specific fields
     */
    fallbackValues?: Record<string, unknown>;
    /**
     * Timeout for object generation in milliseconds
     */
    generationTimeout?: number;
    /**
     * Whether to validate and fix type mismatches
     */
    fixTypeMismatches?: boolean;
    /**
     * Custom repair function for malformed JSON or validation errors
     * If provided, this will be used instead of the default jsonrepair
     */
    repairText?: RepairTextFunction;
    /**
     * Whether to enable automatic JSON repair for malformed LLM outputs
     * Default: true (enabled by default for better reliability)
     * Handles 14+ types of JSON issues including Python constants, JSONP, comments,
     * escaped quotes, URLs in strings, trailing commas, unquoted keys, etc.
     * Set to false to disable all automatic repair
     */
    enableTextRepair?: boolean;
}

interface Options extends Options$1 {
    /**
     * Minimum probability threshold for token selection
     * This parameter is supported by Ollama API but missing from ollama-js TypeScript definitions
     */
    min_p?: number;
}

interface OllamaProviderSettings {
    /**
     * Base URL for the Ollama API (defaults to http://127.0.0.1:11434)
     */
    baseURL?: string;
    /**
     * Custom headers for API requests
     */
    headers?: Record<string, string>;
    /**
     * Custom fetch implementation
     */
    fetch?: typeof fetch;
    /**
     * Existing Ollama client instance to use instead of creating a new one
     */
    client?: Ollama;
}
interface OllamaProvider extends ProviderV2 {
    /**
     * Create a language model instance
     */
    (modelId: string, settings?: OllamaChatSettings): LanguageModelV2;
    /**
     * Create a language model instance with the `chat` method
     */
    chat(modelId: string, settings?: OllamaChatSettings): LanguageModelV2;
    /**
     * Create a language model instance with the `languageModel` method
     */
    languageModel(modelId: string, settings?: OllamaChatSettings): LanguageModelV2;
    /**
     * Create an embedding model instance
     */
    embedding(modelId: string, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
    /**
     * Create an embedding model instance with the `textEmbedding` method
     */
    textEmbedding(modelId: string, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
    /**
     * Create an embedding model instance with the `textEmbeddingModel` method
     */
    textEmbeddingModel(modelId: string, settings?: OllamaEmbeddingSettings): EmbeddingModelV2<string>;
    /**
     * Ollama-specific tools that leverage web search capabilities
     */
    tools: {
        webSearch: (options?: WebSearchToolOptions) => ReturnType<typeof ollamaTools.webSearch>;
        webFetch: (options?: WebFetchToolOptions) => ReturnType<typeof ollamaTools.webFetch>;
    };
}
interface OllamaChatSettings {
    /**
     * Enable structured output mode
     */
    structuredOutputs?: boolean;
    /**
     * Enable reasoning support for models that support it
     */
    reasoning?: boolean;
    /**
     * Enable reliable tool calling with retry and completion mechanisms.
     * Defaults to true whenever function tools are provided; set to false to opt out.
     */
    reliableToolCalling?: boolean;
    /**
     * Tool calling reliability options. These override the sensible defaults used by the
     * built-in reliability layer (maxRetries=2, forceCompletion=true,
     * normalizeParameters=true, validateResults=true).
     */
    toolCallingOptions?: {
        /**
         * Maximum number of retry attempts for tool calls
         */
        maxRetries?: number;
        /**
         * Whether to force completion when tool calls succeed but no final text is generated
         */
        forceCompletion?: boolean;
        /**
         * Whether to normalize parameter names to handle inconsistencies
         */
        normalizeParameters?: boolean;
        /**
         * Whether to validate tool results and attempt recovery
         */
        validateResults?: boolean;
        /**
         * Custom parameter normalization mappings
         */
        parameterMappings?: Record<string, string[]>;
        /**
         * Timeout for tool execution in milliseconds
         */
        toolTimeout?: number;
    };
    /**
     * Enable reliable object generation with retry and repair mechanisms.
     * Defaults to true whenever JSON schemas are used; set to false to opt out.
     */
    reliableObjectGeneration?: boolean;
    /**
     * Object generation reliability options. These override the sensible defaults used by the
     * built-in reliability layer (maxRetries=3, attemptRecovery=true, useFallbacks=true,
     * fixTypeMismatches=true, enableTextRepair=true).
     */
    objectGenerationOptions?: ObjectGenerationOptions;
    /**
     * Additional model parameters - re-exported from ollama-js
     * This automatically includes ALL Ollama parameters including new ones like 'dimensions'
     */
    options?: Partial<Options>;
}
interface OllamaEmbeddingSettings {
    /**
     * Additional embedding parameters
     */
    options?: Partial<Options>;
    /**
     * Dimensions for embedding output (if supported by the model)
     * This is a direct parameter of EmbedRequest, not part of Options
     */
    dimensions?: number;
}
/**
 * Options for configuring Ollama provider calls
 */
interface OllamaProviderOptions {
    /**
     * Additional headers to include in requests
     */
    headers?: Record<string, string>;
}
/**
 * Options for configuring Ollama chat model calls
 */
interface OllamaChatProviderOptions extends OllamaProviderOptions {
    /**
     * Enable structured output mode for object generation
     */
    structuredOutputs?: boolean;
}
/**
 * Options for configuring Ollama embedding model calls
 */
interface OllamaEmbeddingProviderOptions extends OllamaProviderOptions {
    /**
     * Maximum number of embeddings to process in a single call
     */
    maxEmbeddingsPerCall?: number;
}

/**
 * Create an Ollama provider instance for browser environments
 */
declare function createOllama(options?: OllamaProviderSettings): OllamaProvider;
/**
 * Default Ollama provider instance for browser environments
 */
declare const ollama: OllamaProvider;

interface OllamaErrorData {
    message: string;
    code?: string;
    details?: unknown;
}
declare class OllamaError extends Error {
    readonly cause?: unknown;
    readonly data?: OllamaErrorData;
    constructor({ message, cause, data, }: {
        message: string;
        cause?: unknown;
        data?: OllamaErrorData;
    });
    static isOllamaError(error: unknown): error is OllamaError;
}

/**
 * Tool Calling Reliability Utilities for Ollama
 *
 * This module provides utilities to make Ollama tool calling more reliable
 * and deterministic. It addresses common issues like:
 * - Empty final text responses after tool execution
 * - Inconsistent parameter names
 * - Incomplete agent loops
 * - Tool result validation and recovery
 */

interface ToolCallingOptions {
    /**
     * Maximum number of retry attempts for tool calls
     */
    maxRetries?: number;
    /**
     * Whether to force completion when tool calls succeed but no final text is generated
     */
    forceCompletion?: boolean;
    /**
     * Whether to normalize parameter names to handle inconsistencies
     */
    normalizeParameters?: boolean;
    /**
     * Whether to validate tool results and attempt recovery
     */
    validateResults?: boolean;
    /**
     * Custom parameter normalization mappings
     */
    parameterMappings?: Record<string, string[]>;
    /**
     * Timeout for tool execution in milliseconds
     */
    toolTimeout?: number;
}
interface ResolvedToolCallingOptions extends Omit<ToolCallingOptions, 'maxRetries' | 'forceCompletion' | 'normalizeParameters' | 'validateResults'> {
    maxRetries: number;
    forceCompletion: boolean;
    normalizeParameters: boolean;
    validateResults: boolean;
}
interface ToolCallResult {
    success: boolean;
    result?: unknown;
    error?: string;
    normalizedInput?: Record<string, unknown>;
}
interface ReliableToolCallResult {
    text: string;
    toolCalls: Array<{
        toolName: string;
        input: Record<string, unknown>;
    }>;
    toolResults?: Array<{
        toolName: string;
        input: Record<string, unknown>;
        normalizedInput?: Record<string, unknown>;
        result: unknown;
        success: boolean;
        error?: string;
    }>;
    completionMethod: 'natural' | 'forced' | 'incomplete';
    retryCount: number;
    errors?: string[];
}
interface ToolDefinition {
    description: string;
    inputSchema: Record<string, unknown>;
    execute: (params: Record<string, unknown>) => Promise<unknown>;
}

/**
 * generateText - Enhanced generateText with Ollama-specific reliability
 *
 * This wrapper provides response synthesis and enhanced tool calling reliability
 * that addresses the core Ollama limitation: tools execute but no final text is generated.
 */

/**
 * Enhanced options for Ollama-specific reliability features
 */
interface EnhancedOptions {
    /**
     * Enable response synthesis when tools are called but no text is generated
     * @default true
     */
    enableSynthesis?: boolean;
    /**
     * Custom synthesis prompt template
     */
    synthesisPrompt?: string;
    /**
     * Maximum attempts for synthesis
     * @default 2
     */
    maxSynthesisAttempts?: number;
    /**
     * Minimum response length to consider valid
     * @default 10
     */
    minResponseLength?: number;
    /**
     * EXPERIMENTAL: Enable tool calling with structured output (experimental_output)
     *
     * The official AI SDK doesn't support combining toolChoice: 'required' with experimental_output.
     * When enabled, this uses a two-phase approach:
     * 1. Execute tools first (without experimental_output)
     * 2. Generate structured output with tool results injected as context
     *
     * This is NOT standard AI SDK behavior - only enable if you need both features together.
     *
     * @default false
     */
    enableToolsWithStructuredOutput?: boolean;
}
/**
 * Enhanced generateText options that extend the official AI SDK options
 */
type GenerateTextOptions<TOOLS extends ToolSet = ToolSet, OUTPUT = never, OUTPUT_PARTIAL = never> = Parameters<typeof generateText$1<TOOLS, OUTPUT, OUTPUT_PARTIAL>>[0] & {
    /**
     * Enhanced options for Ollama-specific reliability features
     */
    enhancedOptions?: EnhancedOptions;
};
/**
 * Enhanced generateText function with Ollama-specific reliability improvements
 *
 * This function applies synthesis by default when tools execute but return empty responses.
 * The enhancement preserves the original response prototype and all methods/getters.
 *
 * Type parameters are inferred from the options, preserving AI SDK's type inference.
 */
declare function generateText<TOOLS extends ToolSet = ToolSet, OUTPUT = never, OUTPUT_PARTIAL = never>(options: GenerateTextOptions<TOOLS, OUTPUT, OUTPUT_PARTIAL>): ReturnType<typeof generateText$1<TOOLS, OUTPUT, OUTPUT_PARTIAL>>;

interface StreamTextOptions {
    model: LanguageModel;
    system?: string;
    prompt?: string;
    messages?: Parameters<typeof streamText$1>[0]['messages'];
    tools?: Parameters<typeof streamText$1>[0]['tools'];
    maxOutputTokens?: number;
    temperature?: number;
    topP?: number;
    topK?: number;
    presencePenalty?: number;
    frequencyPenalty?: number;
    stopSequences?: string[];
    seed?: number;
    maxRetries?: number;
    abortSignal?: AbortSignal;
    headers?: Record<string, string>;
    /**
     * Enhanced options for Ollama-specific reliability features
     */
    enhancedOptions?: {
        /**
         * Enable enhanced tool calling logging
         * @default true
         */
        enableToolLogging?: boolean;
        /**
         * Enable streaming synthesis when tools execute but no text streams
         * @default true
         */
        enableStreamingSynthesis?: boolean;
        /**
         * Minimum streamed characters before considering it successful
         * @default 10
         */
        minStreamLength?: number;
        /**
         * Timeout in ms to wait for streaming before applying synthesis
         * @default 3000
         */
        synthesisTimeout?: number;
    };
}
/**
 * Enhanced streamText function with Ollama-specific reliability improvements
 */
declare function streamText(options: StreamTextOptions): Promise<ai.StreamTextResult<ai.ToolSet, unknown>>;

export { type GenerateTextOptions, type ObjectGenerationOptions, type OllamaChatProviderOptions, type OllamaChatSettings, type OllamaEmbeddingProviderOptions, type OllamaEmbeddingSettings, OllamaError, type OllamaErrorData, type OllamaProvider, type OllamaProviderOptions, type OllamaProviderSettings, type ReliableToolCallResult, type ResolvedToolCallingOptions, type StreamTextOptions, type ToolCallResult, type ToolCallingOptions, type ToolDefinition, createOllama, generateText, ollama, streamText };
